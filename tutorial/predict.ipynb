{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from crystal_graph import CIFData\n",
    "from crystal_graph import get_train_val_test_loader\n",
    "from crystal_graph import collate_pool\n",
    "from Res_GCN import Res_GCN\n",
    "from test import test_all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load materials CIF data for constructing crystal graph\n",
    "cif_data = CIFData(r\"C:\\Users\\PC\\Downloads\\Res-GCN\\exp_data\")\n",
    "# git properties of crystal graph\n",
    "structure, target, id = cif_data[0]\n",
    "orig_atom_fea_len = structure[0].shape[-1]\n",
    "nbr_fea_len = structure[1].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader for model prediction\n",
    "data_loader, _ = get_train_val_test_loader(cif_data, collate_pool,\n",
    "                                                     batch_size=8,\n",
    "                                                     train_ratio=1,\n",
    "                                                     val_ratio=0,\n",
    "                                                     test_ratio=0,\n",
    "                                                     train_size=None,\n",
    "                                                     test_size=None,\n",
    "                                                     val_size=None,\n",
    "                                                     pin_memory=False,\n",
    "                                                     num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model hyperparameters\n",
    "num_conv_layes = 2\n",
    "num_res_layers = 2\n",
    "num_hidden_layers = 2\n",
    "# create the empty model with the defined hyperparameters\n",
    "# the model is created with the same hyperparameters as the pre-trained Res-GCN model\n",
    "model = Res_GCN(orig_atom_fea_len=orig_atom_fea_len, \n",
    "                 nbr_fea_len=nbr_fea_len, \n",
    "                 atom_fea_len=64, \n",
    "                 n_conv=num_conv_layes,\n",
    "                 n_resconv=num_res_layers,\n",
    "                 h_fea_len=128, \n",
    "                 n_h=num_hidden_layers,\n",
    "                 classification=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Res_GCN(\n",
       "  (embedding): Linear(in_features=92, out_features=64, bias=True)\n",
       "  (convs): ModuleList(\n",
       "    (0-1): 2 x GCB(\n",
       "      (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "      (sigmoid): Sigmoid()\n",
       "      (softplus1): Softplus(beta=1, threshold=20)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus2): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "  )\n",
       "  (res_convs): ModuleList(\n",
       "    (0-1): 2 x GRCB(\n",
       "      (conv): GCB(\n",
       "        (fc_full): Linear(in_features=169, out_features=128, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "        (softplus1): Softplus(beta=1, threshold=20)\n",
       "        (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (softplus2): Softplus(beta=1, threshold=20)\n",
       "      )\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (softplus): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "  )\n",
       "  (conv_to_fc): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (conv_to_fc_softplus): Softplus(beta=1, threshold=20)\n",
       "  (fcs): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (softpluses): ModuleList(\n",
       "    (0): Softplus(beta=1, threshold=20)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pre-trained model parameters and load them into the model\n",
    "para = torch.load(r\"C:\\Users\\PC\\Downloads\\Res-GCN\\pre-trained\\pre-trained-model.pth\")\n",
    "model.load_state_dict(para)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([6.9358], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([5.9969], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([9.5293], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([8.7968], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([11.7157], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([8.7007], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([7.8104], device='cuda:0', grad_fn=<UnbindBackward0>),\n",
       "  tensor([7.5217], device='cuda:0', grad_fn=<UnbindBackward0>)],\n",
       " [tensor([3.]),\n",
       "  tensor([7.]),\n",
       "  tensor([1.]),\n",
       "  tensor([6.]),\n",
       "  tensor([4.]),\n",
       "  tensor([2.]),\n",
       "  tensor([8.]),\n",
       "  tensor([5.])],\n",
       " ['Ba3P4O13',\n",
       "  'Al2Mo3O12',\n",
       "  'LiCr(MoO4)2',\n",
       "  'NaLa(MoO4)2',\n",
       "  'Ba3V2O8',\n",
       "  'LiAl(MoO4)2',\n",
       "  'Sc2Mo3O12',\n",
       "  'NaNd(MoO4)2'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the device to be used for model prediction\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# predict the permittivity of the materials in the dataset\n",
    "test_all_dataset(data_loader=data_loader, model=model, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chosen1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
